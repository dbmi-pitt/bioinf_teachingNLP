{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work through all of the cells in this notebook and answer the questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part I : text preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cells show a very basic process for 'normalizing' text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = '''Alzheimer's disease is a progressive disorder that causes brain cells to waste away (degenerate) and die. Alzheimer's disease is the most common cause of dementia — a continuous decline in thinking, behavioral and social skills that disrupts a person's ability to function independently.\n",
    "\n",
    "The early signs of the disease may be forgetting recent events or conversations. As the disease progresses, a person with Alzheimer's disease will develop severe memory impairment and lose the ability to carry out everyday tasks.\n",
    "\n",
    "Current Alzheimer's disease medications may temporarily improve symptoms or slow the rate of decline. These treatments can sometimes help people with Alzheimer's disease maximize function and maintain independence for a time. Different programs and services can help support people with Alzheimer's disease and their caregivers.\n",
    "\n",
    "There is no treatment that cures Alzheimer's disease or alters the disease process in the brain. In advanced stages of the disease, complications from severe loss of brain function — such as dehydration, malnutrition or infection — result in death.'''\n",
    "\n",
    "adTokens = nltk.word_tokenize(s)\n",
    "print(adTokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adTokLow = [x.lower() for x in adTokens]\n",
    "print(adTokLow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "adTokLowStop = [w for w in adTokLow if not w in stop_words]\n",
    "print(adTokLowStop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "porter = nltk.PorterStemmer()\n",
    "adTokLowStopPorter = [porter.stem(w) for w in adTokLowStop]\n",
    "print(adTokLowStopPorter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1: True/False - stemming always increases the precision of an IR system? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part II -  indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cells show the creation of an inverted index for Herman Melville's Moby Dick. Two indexes are created - one using a stemmed term dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#nltk.download()\n",
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1.tokens[0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(text1.vocab())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxTxt = nltk.Index((word, i) for (i, word) in enumerate(text1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text1.vocab().most_common()[0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1.vocab().most_common()[-200:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "porter = nltk.PorterStemmer()\n",
    "[porter.stem(t) for t in text1.tokens][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxTxtPrtr = nltk.Index((porter.stem(word), i) for (i, word) in enumerate(text1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "idxTxtPrtr['herman']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "idxTxtPrtr['mobi']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2: True/False - Indexing reduces data storage requirements but increases the computational demand placed on IR systems? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part III - Example of term weighting (TF/IDF) using code from https://nlpforhackers.io/tf-idf/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cells create a TF-IDF weighted document-term matrix for a corpus called 'reuters'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import reuters\n",
    " \n",
    "## OPTIONAL Print the categories associated with a file\n",
    "#print (reuters.categories('training/999'))        # [u'interest', u'money-fx']\n",
    " \n",
    "# OPTIONAL Print the contents of the file\n",
    "#print(reuters.raw('test/14829'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    " \n",
    "stop_words = stopwords.words('english') + list(punctuation)\n",
    " \n",
    "def tokenize(text):\n",
    "    words = word_tokenize(text)\n",
    "    words = [w.lower() for w in words]\n",
    "    return [w for w in words if w not in stop_words and not w.isdigit()]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the vocabulary in one pass\n",
    "vocabulary = set()\n",
    "for file_id in reuters.fileids():\n",
    "    words = tokenize(reuters.raw(file_id))\n",
    "    vocabulary.update(words)\n",
    " \n",
    "vocabulary = list(vocabulary)\n",
    "word_index = {w: idx for idx, w in enumerate(vocabulary)}\n",
    " \n",
    "VOCABULARY_SIZE = len(vocabulary)\n",
    "DOCUMENTS_COUNT = len(reuters.fileids())\n",
    " \n",
    "print([VOCABULARY_SIZE, DOCUMENTS_COUNT])      # 51553, 10788"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import math\n",
    "\n",
    "word_freq = collections.defaultdict(lambda: 0)\n",
    "word_idf = collections.defaultdict(lambda: 0)\n",
    "\n",
    "for file_id in reuters.fileids():\n",
    "    words = set(tokenize(reuters.raw(file_id)))\n",
    "    for word in words:\n",
    "        word_freq[word] += 1\n",
    " \n",
    "for word in vocabulary:\n",
    "    word_idf[word] = math.log(DOCUMENTS_COUNT / float(1 + word_freq[word]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(word_freq['deliberations'])\n",
    "print(word_idf['deliberations'])     # 7.49443021503\n",
    "\n",
    "print(word_freq['committee'])\n",
    "print(word_idf['committee'])     # 3.61286641709"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from six import string_types\n",
    "basestring = str\n",
    "\n",
    "def word_tf(word, document):\n",
    "    if isinstance(document, string_types):\n",
    "        document = tokenize(document)\n",
    "    return float(document.count(word)) / len(document)\n",
    "\n",
    " \n",
    "def tf_idf(word, document):\n",
    "    # If not tokenized\n",
    "    if isinstance(document, basestring):\n",
    "        document = tokenize(document)\n",
    "\n",
    "    if word not in word_index:\n",
    "        return .0\n",
    "\n",
    "    return word_tf(word, document) * word_idf[word_index[word]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(word_index['year'])\n",
    "print(word_tf('year',reuters.raw('test/14829')))\n",
    "print(word_idf[word_index['year']])\n",
    "print(tf_idf('year', reuters.raw('test/14829')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf_idf('year', reuters.raw('test/14829')))                 # 0.0209031169481\n",
    "print(tf_idf('following', reuters.raw('test/14829')))            # 0.0306117802726\n",
    "print(tf_idf('provided', reuters.raw('test/14829')))             # 0.0388082713404\n",
    "print(tf_idf('structural', reuters.raw('test/14829')))           # 0.0534999300236\n",
    "print(tf_idf('japanese', reuters.raw('test/14829')))             # 0.0613707825494\n",
    "print(tf_idf('downtrend', reuters.raw('test/14829')))            # 0.068131183773"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('document\\t','\\t'.join(['year','following','provided','structural','japanese','downtrend']))\n",
    "for d in ['test/14826', 'test/14828', 'test/14829', 'test/14832', 'test/14833', 'test/14839', 'test/14840', 'test/14841', 'test/14842', 'test/14843', 'test/14844', 'test/14849', 'test/14852', 'test/14854', 'test/14858', 'test/14859', 'test/14860', 'test/14861', 'test/14862', 'test/14863', 'test/14865', 'test/14867', 'test/14872', 'test/14873', 'test/14875', 'test/14876', 'test/14877', 'test/14881', 'test/14882', 'test/14885', 'test/14886', 'test/14888', 'test/14890', 'test/14891', 'test/14892', 'test/14899', 'test/14900', 'test/14903', 'test/14904', 'test/14907', 'test/14909', 'test/14911', 'test/14912', 'test/14913', 'test/14918', 'test/14919', 'test/14921', 'test/14922', 'test/14923', 'test/14926', 'test/14928', 'test/14930', 'test/14931', 'test/14932', 'test/14933', 'test/14934', 'test/14941', 'test/14943', 'test/14949', 'test/14951', 'test/14954', 'test/14957', 'test/14958', 'test/14959', 'test/14960', 'test/14962', 'test/14963', 'test/14964', 'test/14965', 'test/14967', 'test/14968', 'test/14969', 'test/14970', 'test/14971', 'test/14974', 'test/14975', 'test/14978', 'test/14981', 'test/14982', 'test/14983', 'test/14984', 'test/14985', 'test/14986', 'test/14987', 'test/14988', 'test/14993', 'test/14995', 'test/14998', 'test/15000', 'test/15001', 'test/15002', 'test/15004', 'test/15005', 'test/15006', 'test/15011', 'test/15012', 'test/15013', 'test/15016', 'test/15017', 'test/15020', 'test/15023', 'test/15024', 'test/15026', 'test/15027', 'test/15028', 'test/15029', 'test/15031', 'test/15032', 'test/15033', 'test/15037', 'test/15038', 'test/15043', 'test/15045', 'test/15046', 'test/15048', 'test/15049', 'test/15052', 'test/15053', 'test/15055', 'test/15056', 'test/15060', 'test/15061', 'test/15062', 'test/15063', 'test/15065', 'test/15067', 'test/15069', 'test/15070', 'test/15074', 'test/15077', 'test/15078', 'test/15079', 'test/15082', 'test/15090', 'test/15091', 'test/15092', 'test/15093', 'test/15094', 'test/15095']:\n",
    "    tfIdfL = []\n",
    "    for w in ['year','following','provided','structural','japanese','downtrend']:\n",
    "        tfIdfL.append(str(round(tf_idf(w,reuters.raw(d)),2)))\n",
    "    print(d,':\\t','\\t'.join(tfIdfL))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3: What steps would be required to implement a query over this weighted document-term matrix? Be specific about how you would process the query, calculate query/document similarity scores, and rank the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4: Evaluation measures using pytrec_eval https://arxiv.org/pdf/1805.01597.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cells load the TREC evaluation library and apply it to a synthetic IR system evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytrec_eval\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytrec_eval.supported_measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The following cell has 2 dictionaries (qrel and run). The 'qrel' dictionary creates 20 synthetic mappings from query IDs to relevant documents from a corpus of 12 documents. This serves as a synthetic reference set for an imaginary IR challenge. The 'run' dictionary shows synthetic results from an imaginary system for 2 queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qrel = {\n",
    "    'q1': {\n",
    "        'd1': 0,\n",
    "        'd2': 1,\n",
    "        'd3': 0,\n",
    "        'd4': 0,\n",
    "        'd5': 1,\n",
    "        'd6': 0,\n",
    "        'd7': 0,\n",
    "        'd8': 1,\n",
    "        'd9': 0,\n",
    "        'd10': 0,\n",
    "        'd11': 1,\n",
    "        'd12': 0\n",
    "    },\n",
    "    'q2': {\n",
    "        'd1': 1,\n",
    "        'd2': 0,\n",
    "        'd3': 0,\n",
    "        'd4': 0,\n",
    "        'd5': 0,\n",
    "        'd6': 0,\n",
    "        'd7': 0,\n",
    "        'd8': 1,\n",
    "        'd9': 0,\n",
    "        'd10': 0,\n",
    "        'd11': 0,\n",
    "        'd12': 0\n",
    "    },\n",
    "    'q3': {\n",
    "        'd1': 0,\n",
    "        'd2': 0,\n",
    "        'd3': 0,\n",
    "        'd4': 0,\n",
    "        'd5': 0,\n",
    "        'd6': 0,\n",
    "        'd7': 0,\n",
    "        'd8': 1,\n",
    "        'd9': 0,\n",
    "        'd10': 0,\n",
    "        'd11': 1,\n",
    "        'd12': 0\n",
    "    },\n",
    "    'q4': {\n",
    "        'd1': 1,\n",
    "        'd2': 1,\n",
    "        'd3': 1,\n",
    "        'd4': 0,\n",
    "        'd5': 0,\n",
    "        'd6': 0,\n",
    "        'd7': 1,\n",
    "        'd8': 1,\n",
    "        'd9': 0,\n",
    "        'd10': 0,\n",
    "        'd11': 0,\n",
    "        'd12': 0\n",
    "    },\n",
    "    'q5': {\n",
    "        'd1': 0,\n",
    "        'd2': 1,\n",
    "        'd3': 0,\n",
    "        'd4': 0,\n",
    "        'd5': 0,\n",
    "        'd6': 0,\n",
    "        'd7': 0,\n",
    "        'd8': 0,\n",
    "        'd9': 0,\n",
    "        'd10': 0,\n",
    "        'd11': 1,\n",
    "        'd12': 1\n",
    "    },\n",
    "    'q6': {\n",
    "        'd1': 0,\n",
    "        'd2': 0,\n",
    "        'd3': 0,\n",
    "        'd4': 0,\n",
    "        'd5': 0,\n",
    "        'd6': 0,\n",
    "        'd7': 0,\n",
    "        'd8': 0,\n",
    "        'd9': 0,\n",
    "        'd10': 0,\n",
    "        'd11': 0,\n",
    "        'd12': 0\n",
    "    },    \n",
    "    'q7': {\n",
    "        'd1': 1,\n",
    "        'd2': 1,\n",
    "        'd3': 1,\n",
    "        'd4': 1,\n",
    "        'd5': 1,\n",
    "        'd6': 0,\n",
    "        'd7': 0,\n",
    "        'd8': 0,\n",
    "        'd9': 0,\n",
    "        'd10': 0,\n",
    "        'd11': 0,\n",
    "        'd12': 0\n",
    "    },\n",
    "    'q8': {\n",
    "        'd1': 0,\n",
    "        'd2': 0,\n",
    "        'd3': 0,\n",
    "        'd4': 0,\n",
    "        'd5': 0,\n",
    "        'd6': 0,\n",
    "        'd7': 1,\n",
    "        'd8': 1,\n",
    "        'd9': 1,\n",
    "        'd10': 1,\n",
    "        'd11': 1,\n",
    "        'd12': 0\n",
    "    },\n",
    "    'q9': {\n",
    "        'd1': 0,\n",
    "        'd2': 0,\n",
    "        'd3': 1,\n",
    "        'd4': 1,\n",
    "        'd5': 0,\n",
    "        'd6': 0,\n",
    "        'd7': 1,\n",
    "        'd8': 1,\n",
    "        'd9': 0,\n",
    "        'd10': 0,\n",
    "        'd11': 1,\n",
    "        'd12': 1\n",
    "    },\n",
    "    'q10': {\n",
    "        'd1': 0,\n",
    "        'd2': 0,\n",
    "        'd3': 0,\n",
    "        'd4': 0,\n",
    "        'd5': 0,\n",
    "        'd6': 0,\n",
    "        'd7': 0,\n",
    "        'd8': 1,\n",
    "        'd9': 0,\n",
    "        'd10': 0,\n",
    "        'd11': 1,\n",
    "        'd12': 1\n",
    "    },\n",
    "    'q11': {\n",
    "        'd1': 0,\n",
    "        'd2': 1,\n",
    "        'd3': 0,\n",
    "        'd4': 0,\n",
    "        'd5': 1,\n",
    "        'd6': 0,\n",
    "        'd7': 0,\n",
    "        'd8': 1,\n",
    "        'd9': 0,\n",
    "        'd10': 0,\n",
    "        'd11': 1,\n",
    "        'd12': 0\n",
    "    },\n",
    "    'q12': {\n",
    "        'd1': 1,\n",
    "        'd2': 0,\n",
    "        'd3': 0,\n",
    "        'd4': 0,\n",
    "        'd5': 0,\n",
    "        'd6': 0,\n",
    "        'd7': 0,\n",
    "        'd8': 1,\n",
    "        'd9': 0,\n",
    "        'd10': 0,\n",
    "        'd11': 0,\n",
    "        'd12': 0\n",
    "    },\n",
    "    'q13': {\n",
    "        'd1': 0,\n",
    "        'd2': 0,\n",
    "        'd3': 0,\n",
    "        'd4': 0,\n",
    "        'd5': 0,\n",
    "        'd6': 0,\n",
    "        'd7': 0,\n",
    "        'd8': 1,\n",
    "        'd9': 0,\n",
    "        'd10': 0,\n",
    "        'd11': 1,\n",
    "        'd12': 0\n",
    "    },\n",
    "    'q14': {\n",
    "        'd1': 1,\n",
    "        'd2': 1,\n",
    "        'd3': 1,\n",
    "        'd4': 0,\n",
    "        'd5': 0,\n",
    "        'd6': 0,\n",
    "        'd7': 1,\n",
    "        'd8': 1,\n",
    "        'd9': 0,\n",
    "        'd10': 0,\n",
    "        'd11': 0,\n",
    "        'd12': 0\n",
    "    },\n",
    "    'q15': {\n",
    "        'd1': 0,\n",
    "        'd2': 1,\n",
    "        'd3': 0,\n",
    "        'd4': 0,\n",
    "        'd5': 0,\n",
    "        'd6': 0,\n",
    "        'd7': 0,\n",
    "        'd8': 0,\n",
    "        'd9': 0,\n",
    "        'd10': 0,\n",
    "        'd11': 1,\n",
    "        'd12': 1\n",
    "    },\n",
    "    'q16': {\n",
    "        'd1': 0,\n",
    "        'd2': 0,\n",
    "        'd3': 0,\n",
    "        'd4': 0,\n",
    "        'd5': 0,\n",
    "        'd6': 0,\n",
    "        'd7': 0,\n",
    "        'd8': 0,\n",
    "        'd9': 0,\n",
    "        'd10': 0,\n",
    "        'd11': 0,\n",
    "        'd12': 0\n",
    "    },    \n",
    "    'q17': {\n",
    "        'd1': 1,\n",
    "        'd2': 1,\n",
    "        'd3': 1,\n",
    "        'd4': 1,\n",
    "        'd5': 1,\n",
    "        'd6': 0,\n",
    "        'd7': 0,\n",
    "        'd8': 0,\n",
    "        'd9': 0,\n",
    "        'd10': 0,\n",
    "        'd11': 0,\n",
    "        'd12': 0\n",
    "    },\n",
    "    'q18': {\n",
    "        'd1': 0,\n",
    "        'd2': 0,\n",
    "        'd3': 0,\n",
    "        'd4': 0,\n",
    "        'd5': 0,\n",
    "        'd6': 0,\n",
    "        'd7': 1,\n",
    "        'd8': 1,\n",
    "        'd9': 1,\n",
    "        'd10': 1,\n",
    "        'd11': 1,\n",
    "        'd12': 0\n",
    "    },\n",
    "    'q19': {\n",
    "        'd1': 0,\n",
    "        'd2': 0,\n",
    "        'd3': 1,\n",
    "        'd4': 1,\n",
    "        'd5': 0,\n",
    "        'd6': 0,\n",
    "        'd7': 1,\n",
    "        'd8': 1,\n",
    "        'd9': 0,\n",
    "        'd10': 0,\n",
    "        'd11': 1,\n",
    "        'd12': 1\n",
    "    },\n",
    "    'q20': {\n",
    "        'd1': 0,\n",
    "        'd2': 0,\n",
    "        'd3': 0,\n",
    "        'd4': 0,\n",
    "        'd5': 0,\n",
    "        'd6': 0,\n",
    "        'd7': 0,\n",
    "        'd8': 1,\n",
    "        'd9': 0,\n",
    "        'd10': 0,\n",
    "        'd11': 1,\n",
    "        'd12': 1\n",
    "    }\n",
    "}\n",
    "\n",
    "# q1 run:d9>d1>d4>d5>d11  Relevent top 5: \n",
    "run = {\n",
    "    'q1': {\n",
    "        'd1': 1.3,\n",
    "        'd2': 0.4,\n",
    "        'd3': 0.3,\n",
    "        'd4': 1.2,\n",
    "        'd5': 1.1,\n",
    "        'd6': 0.5,\n",
    "        'd7': 0.1,\n",
    "        'd8': 0.2,\n",
    "        'd9': 1.5,\n",
    "        'd10': 0.9,\n",
    "        'd11': 1.0,\n",
    "        'd12': 0.8\n",
    "     },\n",
    "    'q2': {\n",
    "        'd1': 1.0,\n",
    "        'd2': 1.4,\n",
    "        'd3': 1.3,\n",
    "        'd4': 0.2,\n",
    "        'd5': 0.1,\n",
    "        'd6': 1.5,\n",
    "        'd7': 0.4,\n",
    "        'd8': 0.5,\n",
    "        'd9': 1.1,\n",
    "        'd10': 0.9,\n",
    "        'd11': 0.7,\n",
    "        'd12': 0.8\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The following cells show how to evaluate the imaginary IR system using the two queries and the TREC measures. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = pytrec_eval.RelevanceEvaluator(\n",
    "    qrel, {'recall'})\n",
    "print(json.dumps(evaluator.evaluate(run), indent=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = pytrec_eval.RelevanceEvaluator(\n",
    "    qrel, {'P'})\n",
    "print(json.dumps(evaluator.evaluate(run), indent=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = pytrec_eval.RelevanceEvaluator(\n",
    "    qrel, {'11pt_avg'})\n",
    "print(json.dumps(evaluator.evaluate(run), indent=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = pytrec_eval.RelevanceEvaluator(\n",
    "    qrel, {'map'})\n",
    "print(json.dumps(evaluator.evaluate(run), indent=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4: True/False : The set up for a “TREC-like” information retrieval evaluation includes a set of queries and document relevance judgements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 5: True/False: Term weights derived using TF-IDF term weighting follow the three axioms of probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 6: True/False: R-precision is a metric that is useful for assessing IR system performance when there are an unknown number of relevant documents in a very large corpus "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 7: True/False: The balanced harmonic mean of precision and recall (i.e., F-measure) places more emphasis on recall than precision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 8: What are the possible values for interpolated precision at recall level 0?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 9: An IR system returns 8 relevant documents, and 10 non-relevant documents. There are a total of 20 relevant documents in the collection. What is the precision, recall, and F-measure of the system on this search?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 10: What relationship between precision and recall is used to construct an 11-point interpolated precision-recall curve?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 11: Why would the Area Under the Precision Recall Curve make more sense than AUROC for a comparative evaluation of IR systems?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer: "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
